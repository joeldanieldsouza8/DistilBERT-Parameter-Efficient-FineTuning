{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# 1. Install evaluate\n!pip install -q evaluate\n\n# 2. THE FIX: Force install this specific version of protobuf\n!pip install -q \"protobuf==3.20.3\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:36.793512Z","iopub.execute_input":"2025-11-29T16:06:36.793789Z","iopub.status.idle":"2025-11-29T16:06:43.150451Z","shell.execute_reply.started":"2025-11-29T16:06:36.793764Z","shell.execute_reply":"2025-11-29T16:06:43.149193Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"import torch\nimport random\nimport numpy as np\nimport pandas as pd\nimport gc\nimport time\n\n# Import Hugging Face libraries\nimport evaluate\nfrom datasets import load_dataset, Dataset, DatasetDict, IterableDataset, IterableDatasetDict\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding, EvalPrediction\nfrom peft import LoraConfig, TaskType, get_peft_model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.152392Z","iopub.execute_input":"2025-11-29T16:06:43.152731Z","iopub.status.idle":"2025-11-29T16:06:43.158951Z","shell.execute_reply.started":"2025-11-29T16:06:43.152695Z","shell.execute_reply":"2025-11-29T16:06:43.158212Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Import the Python types\nfrom typing import List, Dict, Any, Tuple, cast, Optional\n\nfrom dataclasses import dataclass, asdict","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.160270Z","iopub.execute_input":"2025-11-29T16:06:43.160506Z","iopub.status.idle":"2025-11-29T16:06:43.188253Z","shell.execute_reply.started":"2025-11-29T16:06:43.160488Z","shell.execute_reply":"2025-11-29T16:06:43.187602Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"SEED = 42\nTRAIN_SAMPLE_SIZE = 3000\nTOTAL_TRIALS = 20\nNUM_LABELS = 6\nMAX_LENGTH = 128\nMODEL = \"distilbert-base-uncased\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.190080Z","iopub.execute_input":"2025-11-29T16:06:43.190302Z","iopub.status.idle":"2025-11-29T16:06:43.207470Z","shell.execute_reply.started":"2025-11-29T16:06:43.190286Z","shell.execute_reply":"2025-11-29T16:06:43.206751Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def set_global_seed(seed: int):\n  \"\"\"\n  Set the global seed for reproducibility.\n  \"\"\"\n  random.seed(seed)\n  np.random.seed(seed)\n  torch.manual_seed(seed)\n\n  # Check if CUDA GPU is available\n  if torch.cuda.is_available():\n    torch.cuda.manual_seed(seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.208153Z","iopub.execute_input":"2025-11-29T16:06:43.208385Z","iopub.status.idle":"2025-11-29T16:06:43.222451Z","shell.execute_reply.started":"2025-11-29T16:06:43.208366Z","shell.execute_reply":"2025-11-29T16:06:43.221731Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"set_global_seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.223266Z","iopub.execute_input":"2025-11-29T16:06:43.223580Z","iopub.status.idle":"2025-11-29T16:06:43.244534Z","shell.execute_reply.started":"2025-11-29T16:06:43.223559Z","shell.execute_reply":"2025-11-29T16:06:43.243867Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"@dataclass(frozen=True, order=True)\nclass LoraHyperparameters:\n  learning_rate: float\n  warmup_ratio: float\n  rank: int\n  alpha: int\n  dropout: float\n  target_modules: List[str]\n\n  @staticmethod # The 'generate_random_hyperparameters' doesn't take an instance of 'self', hence why we use '@staticmethod'\n  def generate_random_hyperparameters() -> 'LoraHyperparameters':\n\n    # Target modules: (Attention Only) OR (Attention + Feedforward)\n      # Option A: [\"q_lin\", \"v_lin\"]\n      # Option B: [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n    module_choice = random.choice([\"attn\", \"attn_ffn\"])\n\n    if module_choice == \"attn\":\n        target_modules = [\"q_lin\", \"v_lin\"]\n    else:\n        target_modules = [\"q_lin\", \"v_lin\", \"ffn.lin1\", \"ffn.lin2\"]\n\n    # Return an instance of the LoraHyperparameters class\n    return LoraHyperparameters(\n      learning_rate=random.uniform(5e-6, 5e-4), # Learning rate is a continous value\n      warmup_ratio=random.choice([0.0, 0.06, 0.1]), # Warm-up ratio is a discrete value\n      rank=random.choice([2, 4, 8, 16, 24]), # LoRA rank is a continous value\n      alpha = random.choice([8, 16, 32, 64, 96]), # Alpha is a discrete value\n      dropout = random.choice([0, 0.05, 0.1, 0.2]), # Dropout is a discrete value\n      target_modules=target_modules\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.245233Z","iopub.execute_input":"2025-11-29T16:06:43.245487Z","iopub.status.idle":"2025-11-29T16:06:43.254404Z","shell.execute_reply.started":"2025-11-29T16:06:43.245466Z","shell.execute_reply":"2025-11-29T16:06:43.253839Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"class DataManager:\n  def __init__(self, model_name: str = MODEL):\n    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n    self.dataset: Optional[Dict[str, Any]] = None\n\n  def prepare_data(self) -> Dict[str, Any]:\n    \"\"\"\n    Loads the dataset and processes it.\n    \"\"\"\n\n    # Check if the dataset is correctly loaded into the instance memory\n    if self.dataset is not None:\n        return self.dataset\n\n    print(\"Loading and processing data...\")\n\n    # Load full dataset\n    full_dataset = cast(DatasetDict, load_dataset(\"dair-ai/emotion\"))\n\n    # Use seed to ensure every run uses the SAME subset of data\n    train_subset = full_dataset[\"train\"].shuffle(seed=SEED).select(range(TRAIN_SAMPLE_SIZE))\n\n    # Private helper method for text embeddings\n    def _tokenize(examples):\n      return self.tokenizer(\n        examples[\"text\"],\n        truncation=True,\n        padding=\"max_length\",\n        max_length=MAX_LENGTH\n      )\n\n    tokenized_train_dataset = train_subset.map(_tokenize, batched=True)\n    tokenized_validation_dataset = full_dataset[\"validation\"].map(_tokenize, batched=True)\n\n    self.dataset = {\n        \"train\": tokenized_train_dataset,\n        \"validation\": tokenized_validation_dataset,\n        \"tokenizer\": self.tokenizer,\n        \"num_labels\": NUM_LABELS\n    }\n\n    print(\"Data preparation complete.\")\n\n    return self.dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.255205Z","iopub.execute_input":"2025-11-29T16:06:43.255672Z","iopub.status.idle":"2025-11-29T16:06:43.269704Z","shell.execute_reply.started":"2025-11-29T16:06:43.255651Z","shell.execute_reply":"2025-11-29T16:06:43.269170Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"data_manager = DataManager()\ndata_bundle = data_manager.prepare_data()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:43.270297Z","iopub.execute_input":"2025-11-29T16:06:43.270453Z","iopub.status.idle":"2025-11-29T16:06:48.578534Z","shell.execute_reply.started":"2025-11-29T16:06:43.270441Z","shell.execute_reply":"2025-11-29T16:06:48.577769Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04c5509a9e864b63b9f46c94bc6eed13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da6bbb4996a64d5b95d8765ee1914d21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba9be379ca0141369641b4bb254c98ae"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b2565b80a1c4d3f9b822011b22572d9"}},"metadata":{}},{"name":"stdout","text":"Loading and processing data...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6506bd18d56e4ed5ac22b6bb486f26a1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/train-00000-of-00001.parquet:   0%|          | 0.00/1.03M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d362c14a6e44dde88dabd169a26076a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/validation-00000-of-00001.parquet:   0%|          | 0.00/127k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae435673b1794fd3a9586b796d274c4e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"split/test-00000-of-00001.parquet:   0%|          | 0.00/129k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d19687a44ee34a5e885a2daa0d11b335"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4107f4451a2c4f32ad35021cf5aa73c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b3cbe15f2234c48aef6f2f072f74baa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8829c2c19d04c6c8fe5094f43c80a36"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"210869d788c84292a1a704d0c0b890ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2eadc9ee5cb8499c9e94c02bd96873ef"}},"metadata":{}},{"name":"stdout","text":"Data preparation complete.\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"class RandomSearchExperiment:\n  def __init__(self, data_bundle: Dict[str, Any], total_trials: int = 20):\n    self.data = data_bundle\n    self.total_trials = total_trials\n    self.results: List[Dict[str, Any]] = []\n    self.metric = evaluate.load(\"accuracy\")\n\n  def _compute_metrics(self, eval_pred: EvalPrediction) -> Dict[str, float]:\n    \"\"\"\n    Calculates accuracy during training.\n    \"\"\"\n    predictions, labels = eval_pred\n    predictions = np.argmax(predictions, axis=1)\n\n    result = self.metric.compute(predictions=predictions, references=labels)\n\n    return cast(Dict[str, float], result)\n\n  def _cleanup_memory(self, model, trainer):\n    \"\"\"\n    Forcefully clears GPU memory.\n    \"\"\"\n    del model\n    del trainer\n    torch.cuda.empty_cache()\n    gc.collect()\n\n  def run_single_trial(self, trial_id: int, params: LoraHyperparameters, seed: Optional[int] = None) -> Tuple[float, float]:\n    \"\"\"\n    Executes one training run with specific hyperparameters.\n    \"\"\"\n    print(f\"\\n[Trial {trial_id}/{self.total_trials}] Starting...\")\n    print(f\"   Params: Rank={params.rank}, Alpha={params.alpha}, LR={params.learning_rate:.2e}\")\n\n    # # Add 'trial_id' to the 'SEED' to ensure each trial is unique\n    # current_seed = SEED + trial_id\n\n    if seed is not None:\n      current_seed = seed\n    else:\n      current_seed = SEED + trial_id\n\n    # Initialize the base model\n    model = AutoModelForSequenceClassification.from_pretrained(\n      MODEL,\n      num_labels=self.data[\"num_labels\"]\n    )\n\n    # LoRA configuration\n    peft_config = LoraConfig(\n      task_type=TaskType.SEQ_CLS,\n      r=params.rank,\n      lora_alpha=params.alpha,\n      lora_dropout=params.dropout,\n      target_modules=params.target_modules\n    )\n\n    model = get_peft_model(model, peft_config)\n\n    args = TrainingArguments(\n      output_dir=f\"./results/trial_{trial_id}\",\n      learning_rate=params.learning_rate,\n      per_device_train_batch_size=16,\n      per_device_eval_batch_size=16,\n      num_train_epochs=3,\n      warmup_ratio=params.warmup_ratio,\n      weight_decay=0.01,\n      eval_strategy=\"epoch\", # Updated from 'evaluation_strategy'\n      save_strategy=\"no\", # Don't save checkpoints (saves disk space)\n      logging_strategy=\"epoch\",\n      seed=current_seed,\n      report_to=\"none\", # Disable WANDB\n      load_best_model_at_end=False,\n      optim=\"adamw_torch\"\n    )\n\n    # Initialize the Trainer\n    trainer = Trainer(\n      model=model,\n      args=args,\n      train_dataset=self.data[\"train\"],\n      eval_dataset=self.data[\"validation\"],\n      data_collator=DataCollatorWithPadding(tokenizer=self.data[\"tokenizer\"]),\n      compute_metrics=self._compute_metrics\n    )\n\n    start_time = time.time()\n\n    # Train and Evaluate\n    trainer.train()\n    eval_results = trainer.evaluate()\n\n    end_time = time.time()\n    trial_duration = end_time - start_time\n\n    accuracy = eval_results[\"eval_accuracy\"]\n\n    print(f\"   [Trial {trial_id}] Complete. Accuracy: {accuracy:.4%} | Time: {trial_duration:.2f}s\")\n\n    # Cleanup the memory\n    self._cleanup_memory(model, trainer)\n\n    return accuracy, trial_duration\n\n  def verify_top_trials(self, top_k: int = 5, seeds: List[int] = [42, 43, 44]):\n    # Check if there are any results\n    if not self.results:\n      print(\"No results found in memory. Please run experiment first.\")\n      return\n\n    print(f\"\\n\" + \"=\"*40)\n    print(f\"STARTING ROBUSTNESS VERIFICATION (Top {top_k} Models)\")\n    print(\"=\"*40)\n\n    # Sort the results by accuracy in descending order and slice the top K\n    sorted_results = sorted(self.results, key=lambda x: x[\"accuracy\"], reverse=True)\n    top_k_results = sorted_results[:top_k]\n\n    robustness_data: List[Dict[str, Any]] = []\n\n    for i, trial in enumerate(top_k_results, start=1):\n      trial_id = trial[\"trial_id\"]\n      original_accuracy = trial[\"accuracy\"] # Renamed to avoid confusion\n      \n      print(f\"\\n>>> Verifying Rank {i}: Trial {trial_id} (Original Acc: {original_accuracy:.4%})\")\n\n      params = LoraHyperparameters(\n          learning_rate=trial[\"learning_rate\"],\n          warmup_ratio=trial[\"warmup_ratio\"],\n          rank=trial[\"rank\"],\n          alpha=trial[\"alpha\"],\n          dropout=trial[\"dropout\"],\n          target_modules=trial[\"target_modules\"]\n      )\n\n      current_accuracies = []\n\n      for seed in seeds:\n        # Fixed Argument passing syntax here\n        new_acc, _ = self.run_single_trial(trial_id, params, seed=seed)\n        current_accuracies.append(new_acc)\n\n        # Explicit garbage collection\n        torch.cuda.empty_cache()\n        gc.collect()\n      \n      mean_accuracy = np.mean(current_accuracies)\n      std_accuracy = np.std(current_accuracies)\n      \n      print(f\"    -> Result: {mean_accuracy:.4%} Â± {std_accuracy:.4%}\")\n\n      entry = {\n          \"trial_id\": trial_id,\n          \"original_accuracy\": original_accuracy,\n          \"mean_accuracy\": mean_accuracy,\n          \"std_accuracy\": std_accuracy,\n          \"all_seed_accuracies\": current_accuracies\n      }\n\n      entry.update(asdict(params))\n      robustness_data.append(entry)\n\n    df_robust = pd.DataFrame(robustness_data)\n    filename = \"robustness_verification_results.csv\"\n    df_robust.to_csv(filename, index=False)\n\n    print(f\"\\nRobustness verification complete. Saved to {filename}\")\n\n\n  def run_experiment(self):\n    \"\"\"\n    Main loop to execute the random search.\n    \"\"\"\n    print(f\"Starting Random Search for {self.total_trials} trials...\")\n\n    for i in range(self.total_trials):\n      trial_id = i + 1\n\n      try:\n        # Generate the random hyperparameters\n        params = LoraHyperparameters.generate_random_hyperparameters()\n\n        # Run the current trial\n        accuracy, trial_duration = self.run_single_trial(trial_id=trial_id, params=params)\n\n        # Log the current result\n        result_entry = {\n            \"trial_id\": trial_id,\n            \"accuracy\": accuracy,\n            \"trial_duration_in_seconds\": trial_duration\n        }\n\n        # Flatten parameters into the dict for easier CSV saving\n        result_entry.update(asdict(params))\n\n        self.results.append(result_entry)\n\n      except Exception as e:\n        print(f\"!!! CRITICAL ERROR in Trial {trial_id}: {e}\")\n\n        # Clean the memory\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    print(\"\\nExperiment Completed.\")\n\n  def save_results(self, filename=\"random_search_results.csv\"):\n    \"\"\"\n    Saves results to CSV and prints summary stats.\n    \"\"\"\n    if not self.results:\n      print(\"No results to save.\")\n      return\n\n    df = pd.DataFrame(self.results)\n\n    # Summary\n    best_idx = df['accuracy'].idxmax()\n    best_row = df.loc[best_idx]\n\n    best_accuracy = best_row['accuracy'].item()\n    best_trial_id = int(best_row['trial_id'].item())\n\n    print(\"\\n\" + \"=\"*40)\n    print(\"RESULTS SUMMARY\")\n    print(\"=\"*40)\n    print(f\"Best Accuracy: {best_accuracy:.4%} (Trial {best_trial_id})\")\n    print(f\"Mean Accuracy: {df['accuracy'].mean():.4%}\")\n    print(f\"Std Dev      : {df['accuracy'].std():.4%}\")\n\n    # Export\n    df.to_csv(filename, index=False)\n\n    print(f\"Results saved to {filename}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:48.580237Z","iopub.execute_input":"2025-11-29T16:06:48.580457Z","iopub.status.idle":"2025-11-29T16:06:48.598015Z","shell.execute_reply.started":"2025-11-29T16:06:48.580438Z","shell.execute_reply":"2025-11-29T16:06:48.597281Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"# Create the Experiment\nexperiment = RandomSearchExperiment(data_bundle, total_trials=TOTAL_TRIALS)\n\nstart_experiment_time = time.time()\n\n# Run the full experiment of 20 trials\nexperiment.run_experiment()\n\nend_experiment_time = time.time()\n\ntotal_duration = end_experiment_time - start_experiment_time\n\nprint(f\"Total time taken to complete 20 experiments: {str(total_duration)} seconds\")\n\n# Save the results from running the full experiment\nexperiment.save_results()\n\nexperiment.verify_top_trials(top_k=5, seeds=[42, 43, 44])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T16:06:48.598843Z","iopub.execute_input":"2025-11-29T16:06:48.599573Z","iopub.status.idle":"2025-11-29T16:44:01.281406Z","shell.execute_reply.started":"2025-11-29T16:06:48.599549Z","shell.execute_reply":"2025-11-29T16:44:01.280717Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"75874329448d41b5aab944ea7f845b51"}},"metadata":{}},{"name":"stdout","text":"Starting Random Search for 20 trials...\n\n[Trial 1/20] Starting...\n   Params: Rank=4, Alpha=16, LR=1.74e-05\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5fd6f0e9488438b9146986af5daab4a"}},"metadata":{}},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nNo label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.650400</td>\n      <td>1.564063</td>\n      <td>0.352000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.537100</td>\n      <td>1.530567</td>\n      <td>0.474500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.507500</td>\n      <td>1.513372</td>\n      <td>0.480500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 1] Complete. Accuracy: 48.0500% | Time: 59.08s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 2/20] Starting...\n   Params: Rank=16, Alpha=32, LR=1.47e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.222200</td>\n      <td>0.881532</td>\n      <td>0.681500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.734500</td>\n      <td>0.657039</td>\n      <td>0.754000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.591500</td>\n      <td>0.614852</td>\n      <td>0.776500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 2] Complete. Accuracy: 77.6500% | Time: 57.82s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=2.62e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.117300</td>\n      <td>0.659879</td>\n      <td>0.739500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.507300</td>\n      <td>0.446362</td>\n      <td>0.853000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.350700</td>\n      <td>0.399791</td>\n      <td>0.866500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 86.6500% | Time: 67.10s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 4/20] Starting...\n   Params: Rank=2, Alpha=32, LR=2.12e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.108200</td>\n      <td>0.632076</td>\n      <td>0.756000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.490300</td>\n      <td>0.459008</td>\n      <td>0.840000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.320800</td>\n      <td>0.375281</td>\n      <td>0.877000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 4] Complete. Accuracy: 87.7000% | Time: 67.31s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 5/20] Starting...\n   Params: Rank=24, Alpha=16, LR=2.03e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.254500</td>\n      <td>0.831445</td>\n      <td>0.685000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.664300</td>\n      <td>0.590105</td>\n      <td>0.787500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.535300</td>\n      <td>0.551326</td>\n      <td>0.798000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 5] Complete. Accuracy: 79.8000% | Time: 59.47s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 6/20] Starting...\n   Params: Rank=16, Alpha=96, LR=3.59e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.420900</td>\n      <td>1.098862</td>\n      <td>0.576500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.957400</td>\n      <td>0.848449</td>\n      <td>0.702000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.778400</td>\n      <td>0.773710</td>\n      <td>0.719000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 6] Complete. Accuracy: 71.9000% | Time: 67.53s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 7/20] Starting...\n   Params: Rank=24, Alpha=32, LR=7.03e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.352300</td>\n      <td>0.998731</td>\n      <td>0.657500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.812700</td>\n      <td>0.708106</td>\n      <td>0.722000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.629500</td>\n      <td>0.642923</td>\n      <td>0.756500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 7] Complete. Accuracy: 75.6500% | Time: 67.77s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 8/20] Starting...\n   Params: Rank=8, Alpha=96, LR=1.75e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.103800</td>\n      <td>0.733828</td>\n      <td>0.723500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.595500</td>\n      <td>0.528691</td>\n      <td>0.803500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.443900</td>\n      <td>0.487283</td>\n      <td>0.827000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 8] Complete. Accuracy: 82.7000% | Time: 59.08s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=4.29e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:03, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.957800</td>\n      <td>0.531035</td>\n      <td>0.827000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.401700</td>\n      <td>0.340540</td>\n      <td>0.884500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.222800</td>\n      <td>0.321413</td>\n      <td>0.896500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 89.6500% | Time: 67.88s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 10/20] Starting...\n   Params: Rank=4, Alpha=16, LR=4.20e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.115500</td>\n      <td>0.632312</td>\n      <td>0.776500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.542900</td>\n      <td>0.457145</td>\n      <td>0.840500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.380200</td>\n      <td>0.426062</td>\n      <td>0.849500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 10] Complete. Accuracy: 84.9500% | Time: 59.66s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 11/20] Starting...\n   Params: Rank=24, Alpha=64, LR=3.20e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.478100</td>\n      <td>1.147880</td>\n      <td>0.567000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.038600</td>\n      <td>0.946631</td>\n      <td>0.665500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.880000</td>\n      <td>0.877614</td>\n      <td>0.686500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 11] Complete. Accuracy: 68.6500% | Time: 67.83s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=2.31e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.140000</td>\n      <td>0.639930</td>\n      <td>0.757000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.527000</td>\n      <td>0.452299</td>\n      <td>0.839500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.376600</td>\n      <td>0.411361</td>\n      <td>0.851000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 85.1000% | Time: 59.52s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 13/20] Starting...\n   Params: Rank=16, Alpha=64, LR=2.22e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.108000</td>\n      <td>0.662978</td>\n      <td>0.750000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.566000</td>\n      <td>0.501536</td>\n      <td>0.818000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.427500</td>\n      <td>0.472808</td>\n      <td>0.827500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 13] Complete. Accuracy: 82.7500% | Time: 59.77s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.94e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.941500</td>\n      <td>0.604808</td>\n      <td>0.788000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.485200</td>\n      <td>0.461175</td>\n      <td>0.849000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.345300</td>\n      <td>0.411094</td>\n      <td>0.866500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 86.6500% | Time: 59.30s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 15/20] Starting...\n   Params: Rank=8, Alpha=96, LR=2.39e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.154600</td>\n      <td>0.712902</td>\n      <td>0.750500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.575200</td>\n      <td>0.510407</td>\n      <td>0.813500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.414800</td>\n      <td>0.462051</td>\n      <td>0.831000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 15] Complete. Accuracy: 83.1000% | Time: 59.36s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 16/20] Starting...\n   Params: Rank=2, Alpha=16, LR=1.87e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.303700</td>\n      <td>0.852179</td>\n      <td>0.670500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.715800</td>\n      <td>0.635811</td>\n      <td>0.772000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.570900</td>\n      <td>0.595866</td>\n      <td>0.788500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 16] Complete. Accuracy: 78.8500% | Time: 59.73s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 17/20] Starting...\n   Params: Rank=4, Alpha=8, LR=1.07e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:55, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.465500</td>\n      <td>1.157314</td>\n      <td>0.572500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.005300</td>\n      <td>0.893083</td>\n      <td>0.665500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.838900</td>\n      <td>0.836006</td>\n      <td>0.690500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 17] Complete. Accuracy: 69.0500% | Time: 59.70s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 18/20] Starting...\n   Params: Rank=16, Alpha=8, LR=4.69e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.610000</td>\n      <td>1.473416</td>\n      <td>0.503500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.311100</td>\n      <td>1.206231</td>\n      <td>0.549000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.172100</td>\n      <td>1.163281</td>\n      <td>0.561500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 18] Complete. Accuracy: 56.1500% | Time: 59.37s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 19/20] Starting...\n   Params: Rank=8, Alpha=16, LR=1.45e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.181400</td>\n      <td>0.814479</td>\n      <td>0.695000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.662700</td>\n      <td>0.583858</td>\n      <td>0.801000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.495500</td>\n      <td>0.520616</td>\n      <td>0.815500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 19] Complete. Accuracy: 81.5500% | Time: 66.58s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 20/20] Starting...\n   Params: Rank=8, Alpha=32, LR=9.49e-05\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.229800</td>\n      <td>0.884214</td>\n      <td>0.673000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.704500</td>\n      <td>0.618960</td>\n      <td>0.770500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.532100</td>\n      <td>0.559447</td>\n      <td>0.798000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 20] Complete. Accuracy: 79.8000% | Time: 65.96s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nExperiment Completed.\nTotal time taken to complete 20 experiments: 1265.4200508594513 seconds\n\n========================================\nRESULTS SUMMARY\n========================================\nBest Accuracy: 89.6500% (Trial 9)\nMean Accuracy: 77.8175%\nStd Dev      : 10.6444%\nResults saved to random_search_results.csv\n\n========================================\nSTARTING ROBUSTNESS VERIFICATION (Top 5 Models)\n========================================\n\n>>> Verifying Rank 1: Trial 9 (Original Acc: 89.6500%)\n\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=4.29e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.948800</td>\n      <td>0.491954</td>\n      <td>0.825000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.354400</td>\n      <td>0.331487</td>\n      <td>0.897500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.178700</td>\n      <td>0.306983</td>\n      <td>0.907500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 90.7500% | Time: 66.48s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=4.29e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.946700</td>\n      <td>0.577624</td>\n      <td>0.797500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.377400</td>\n      <td>0.345799</td>\n      <td>0.891500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.200900</td>\n      <td>0.323856</td>\n      <td>0.902000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 90.2000% | Time: 66.60s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 9/20] Starting...\n   Params: Rank=4, Alpha=64, LR=4.29e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.956300</td>\n      <td>0.479992</td>\n      <td>0.835000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.383700</td>\n      <td>0.349368</td>\n      <td>0.888500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.210200</td>\n      <td>0.334841</td>\n      <td>0.902000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 9] Complete. Accuracy: 90.2000% | Time: 66.51s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 90.3833% Â± 0.2593%\n\n>>> Verifying Rank 2: Trial 4 (Original Acc: 87.7000%)\n\n[Trial 4/20] Starting...\n   Params: Rank=2, Alpha=32, LR=2.12e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:01, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.116000</td>\n      <td>0.683041</td>\n      <td>0.762000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.520200</td>\n      <td>0.443224</td>\n      <td>0.847000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.322400</td>\n      <td>0.391210</td>\n      <td>0.870000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 4] Complete. Accuracy: 87.0000% | Time: 66.70s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 4/20] Starting...\n   Params: Rank=2, Alpha=32, LR=2.12e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.123600</td>\n      <td>0.682884</td>\n      <td>0.736500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.523800</td>\n      <td>0.457701</td>\n      <td>0.837000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.349700</td>\n      <td>0.402349</td>\n      <td>0.863000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 4] Complete. Accuracy: 86.3000% | Time: 66.83s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 4/20] Starting...\n   Params: Rank=2, Alpha=32, LR=2.12e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.106800</td>\n      <td>0.640440</td>\n      <td>0.757000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.505000</td>\n      <td>0.440221</td>\n      <td>0.859500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.331200</td>\n      <td>0.393077</td>\n      <td>0.872500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 4] Complete. Accuracy: 87.2500% | Time: 66.99s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 86.8500% Â± 0.4021%\n\n>>> Verifying Rank 3: Trial 3 (Original Acc: 86.6500%)\n\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=2.62e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.141600</td>\n      <td>0.666427</td>\n      <td>0.772000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.519600</td>\n      <td>0.432481</td>\n      <td>0.849000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.329300</td>\n      <td>0.391995</td>\n      <td>0.865500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 86.5500% | Time: 66.86s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=2.62e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.154900</td>\n      <td>0.674265</td>\n      <td>0.738000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.527600</td>\n      <td>0.452401</td>\n      <td>0.841000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.355700</td>\n      <td>0.403919</td>\n      <td>0.865000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 86.5000% | Time: 66.81s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 3/20] Starting...\n   Params: Rank=2, Alpha=16, LR=2.62e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 01:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.122400</td>\n      <td>0.612447</td>\n      <td>0.763000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.501500</td>\n      <td>0.441996</td>\n      <td>0.852500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.343200</td>\n      <td>0.385642</td>\n      <td>0.874000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:04]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 3] Complete. Accuracy: 87.4000% | Time: 66.82s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 86.8167% Â± 0.4130%\n\n>>> Verifying Rank 4: Trial 14 (Original Acc: 86.6500%)\n\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.94e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.935700</td>\n      <td>0.595622</td>\n      <td>0.783000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.456200</td>\n      <td>0.416383</td>\n      <td>0.857000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.320200</td>\n      <td>0.387908</td>\n      <td>0.869500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 86.9500% | Time: 58.07s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.94e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.949900</td>\n      <td>0.609337</td>\n      <td>0.778500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.476200</td>\n      <td>0.427469</td>\n      <td>0.844000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.333900</td>\n      <td>0.397376</td>\n      <td>0.870500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 87.0500% | Time: 58.08s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 14/20] Starting...\n   Params: Rank=4, Alpha=32, LR=4.94e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.945900</td>\n      <td>0.535714</td>\n      <td>0.796000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.454900</td>\n      <td>0.396565</td>\n      <td>0.866500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.309400</td>\n      <td>0.369336</td>\n      <td>0.878500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 14] Complete. Accuracy: 87.8500% | Time: 58.09s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"    -> Result: 87.2833% Â± 0.4028%\n\n>>> Verifying Rank 5: Trial 12 (Original Acc: 85.1000%)\n\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=2.31e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.136300</td>\n      <td>0.667972</td>\n      <td>0.768000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.524600</td>\n      <td>0.485703</td>\n      <td>0.816500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.369600</td>\n      <td>0.435598</td>\n      <td>0.846500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 84.6500% | Time: 58.30s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=2.31e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:53, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.139500</td>\n      <td>0.661010</td>\n      <td>0.745500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.532800</td>\n      <td>0.455840</td>\n      <td>0.836500</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.365400</td>\n      <td>0.416255</td>\n      <td>0.853500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 85.3500% | Time: 58.36s\n","output_type":"stream"},{"name":"stderr","text":"Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\n[Trial 12/20] Starting...\n   Params: Rank=16, Alpha=96, LR=2.31e-04\n","output_type":"stream"},{"name":"stderr","text":"No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='564' max='564' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [564/564 00:54, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.100500</td>\n      <td>0.638761</td>\n      <td>0.764500</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.526200</td>\n      <td>0.473951</td>\n      <td>0.832000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.359800</td>\n      <td>0.426897</td>\n      <td>0.849500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [125/125 00:03]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"   [Trial 12] Complete. Accuracy: 84.9500% | Time: 59.12s\n    -> Result: 84.9833% Â± 0.2867%\n\nRobustness verification complete. Saved to robustness_verification_results.csv\n","output_type":"stream"}],"execution_count":18}]}